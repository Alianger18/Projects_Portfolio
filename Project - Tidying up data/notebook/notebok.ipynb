{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# <center> The Value of Data Pre-processing <center/>\n",
    "<center> <b>DLBDSDQDW01<b/> - Data Quality and Data Wrangling <center/>\n",
    "<center> IU International University of Applied Sciences <center/>"
   ],
   "id": "7370a84267f00342"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this project, we tackle the challenges associated with analyzing real-world and messy datasets. Recognizing the inherent difficulties in seamlessly transitioning from hypothesis formulation to data analysis, this work emphasizes the importance of data cleaning, reshaping, and tidying as foundational steps in the analytical process. By applying Data Wrangling techniques and Quality methods, we aim to uncover patterns and insights, despite the noisy and incomplete nature of the data. This analysis not only highlights the relationships and trends within the dataset but also demonstrates the ability to effectively manage and interpret unstructured data, ultimately supporting informed decision-making.",
   "id": "2dd033242e1a2997"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## List of contents : \n",
    "1. __About the data__\n",
    "2. __Overview__\n",
    "3. __Exploraorty Data Analaysis__\n",
    "4. __Data Wrangling__\n",
    "5. __Data Quality Checks__\n",
    "6. __Conclusion__\n",
    "\n",
    "    About the Author"
   ],
   "id": "c832e7f8db9084ad"
  },
  {
   "cell_type": "markdown",
   "id": "3b07130f",
   "metadata": {},
   "source": "First, we start by importing the required libraries"
  },
  {
   "cell_type": "code",
   "id": "24ea4524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:48:05.514059Z",
     "start_time": "2024-11-25T01:48:05.501783Z"
    }
   },
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. About the data\n",
    "\n",
    "The [data](https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/airline_2m.tar.gz) used in this notebook is only a sample from the original dataset called __The Reporting Carrier On-Time Performance Dataset__ containing information on approximately 200 million domestic US flights reported to the [United States Bureau of Transportation Statistics](https://www.bts.gov/). The dataset contains basic information about each flight (such as date, time, departure airport, arrival airport) and, if applicable, the amount of time the flight was delayed and information about the reason for the delay. A complete overview on the glossary of the data could be found [here](https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/data-preview/index.html).\n",
    "\n",
    "__NOTE__:Due to its large size, it's recommended to download it manually.\n"
   ],
   "id": "692970d29fe2abd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Overview\n",
    "\n",
    "Some initial bullshit\n"
   ],
   "id": "1d41743e904ec431"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's load our dataframe",
   "id": "18f2de1f"
  },
  {
   "cell_type": "code",
   "id": "4bc5a8fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T02:00:18.873445Z",
     "start_time": "2024-11-25T02:00:18.820639Z"
    }
   },
   "source": [
    "# Locating our directory\n",
    "path = Path.cwd()\n",
    "\n",
    "# Read the airline data into pandas dataframe\n",
    "df = pd.read_csv(f'{path.parent}/data/train.csv')\n",
    "\n",
    "# Print the few first rows\n",
    "df.head(15)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  \n",
       "0       0         A/5 21171   7.2500   NaN        S  \n",
       "1       0          PC 17599  71.2833   C85        C  \n",
       "2       0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3       0            113803  53.1000  C123        S  \n",
       "4       0            373450   8.0500   NaN        S  \n",
       "5       0            330877   8.4583   NaN        Q  \n",
       "6       0             17463  51.8625   E46        S  \n",
       "7       1            349909  21.0750   NaN        S  \n",
       "8       2            347742  11.1333   NaN        S  \n",
       "9       0            237736  30.0708   NaN        C  \n",
       "10      1           PP 9549  16.7000    G6        S  \n",
       "11      0            113783  26.5500  C103        S  \n",
       "12      0         A/5. 2151   8.0500   NaN        S  \n",
       "13      5            347082  31.2750   NaN        S  \n",
       "14      0            350406   7.8542   NaN        S  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:48:38.687869Z",
     "start_time": "2024-11-25T01:48:38.680354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the shape of the data\n",
    "print(f\"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ],
   "id": "52f2a8fa5283fa7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 891 rows and 12 columns.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the following, we can see an overview of the data types, missing values, and columns of our dataset.",
   "id": "8d7692f86380577a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:51:26.796946Z",
     "start_time": "2024-11-25T01:51:26.758072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initiating a new dictionary\n",
    "new_dict = {}\n",
    "\n",
    "# Running a loop to gather information\n",
    "for column in df.columns:\n",
    "    new_dict[column] = [df[column].dtype, df[column].isna().sum(), df[column].unique(), len(df[column].unique())]\n",
    "\n",
    "# Constructing the dataframe\n",
    "discover_df = pd.DataFrame(new_dict).transpose().reset_index()\n",
    "discover_df.columns = [\"Columns\", \"Data types\", \"Number of empty values\", \"Unique Values\", \"Number of Unique Values\"]\n",
    "\n",
    "# Print the first few rows\n",
    "discover_df"
   ],
   "id": "ec85cdde8d2f76e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Columns Data types Number of empty values  \\\n",
       "0   PassengerId      int64                      0   \n",
       "1      Survived      int64                      0   \n",
       "2        Pclass      int64                      0   \n",
       "3          Name     object                      0   \n",
       "4           Sex     object                      0   \n",
       "5           Age    float64                    177   \n",
       "6         SibSp      int64                      0   \n",
       "7         Parch      int64                      0   \n",
       "8        Ticket     object                      0   \n",
       "9          Fare    float64                      0   \n",
       "10        Cabin     object                    687   \n",
       "11     Embarked     object                      2   \n",
       "\n",
       "                                        Unique Values Number of Unique Values  \n",
       "0   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...                     891  \n",
       "1                                              [0, 1]                       2  \n",
       "2                                           [3, 1, 2]                       3  \n",
       "3   [Braund, Mr. Owen Harris, Cumings, Mrs. John B...                     891  \n",
       "4                                      [male, female]                       2  \n",
       "5   [22.0, 38.0, 26.0, 35.0, nan, 54.0, 2.0, 27.0,...                      89  \n",
       "6                               [1, 0, 3, 4, 2, 5, 8]                       7  \n",
       "7                               [0, 1, 2, 5, 3, 4, 6]                       7  \n",
       "8   [A/5 21171, PC 17599, STON/O2. 3101282, 113803...                     681  \n",
       "9   [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51....                     248  \n",
       "10  [nan, C85, C123, E46, G6, C103, D56, A6, C23 C...                     148  \n",
       "11                                     [S, C, Q, nan]                       4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Data types</th>\n",
       "      <th>Number of empty values</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Number of Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 1, 2]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>[Braund, Mr. Owen Harris, Cumings, Mrs. John B...</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>[male, female]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>float64</td>\n",
       "      <td>177</td>\n",
       "      <td>[22.0, 38.0, 26.0, 35.0, nan, 54.0, 2.0, 27.0,...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 3, 4, 2, 5, 8]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 5, 3, 4, 6]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>[A/5 21171, PC 17599, STON/O2. 3101282, 113803...</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51....</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>object</td>\n",
       "      <td>687</td>\n",
       "      <td>[nan, C85, C123, E46, G6, C103, D56, A6, C23 C...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>[S, C, Q, nan]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "On this basis, let's proceed to delete the entirely empty columns",
   "id": "72a46f961f4ee96b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:29:21.017650Z",
     "start_time": "2024-11-21T15:29:04.772026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Listing the empty columns\n",
    "columns_to_drop = [\n",
    "    # Redundant information\n",
    "    \"DOT_ID_Reporting_Airline\",\n",
    "    \"IATA_CODE_Reporting_Airline\",\n",
    "    \"OriginAirportID\",\n",
    "    \"OriginAirportSeqID\",\n",
    "    \"OriginCityMarketID\",\n",
    "    \"OriginStateFips\",\n",
    "    \"OriginWac\",\n",
    "    \"DestAirportID\",\n",
    "    \"DestAirportSeqID\",\n",
    "    \"DestCityMarketID\",\n",
    "    \"DestStateFips\",\n",
    "    \"DestWac\",\n",
    "    \"Div1AirportID\",\n",
    "    \"Div1AirportSeqID\",\n",
    "    \"Div1AirportID\",\n",
    "    \"Div1AirportSeqID\",\n",
    "\n",
    "    # Empty columns\n",
    "    \"Div2Airport\",\n",
    "    \"Div2AirportID\",\n",
    "    \"Div2AirportSeqID\",\n",
    "    \"Div2WheelsOn\",\n",
    "    \"Div2TotalGTime\",\n",
    "    \"Div2LongestGTime\",\n",
    "    \"Div2WheelsOff\",\n",
    "    \"Div2TailNum\",\n",
    "    \"Div3Airport\",\n",
    "    \"Div3AirportID\",\n",
    "    \"Div3AirportSeqID\",\n",
    "    \"Div3WheelsOn\",\n",
    "    \"Div3TotalGTime\",\n",
    "    \"Div3LongestGTime\",\n",
    "    \"Div3WheelsOff\",\n",
    "    \"Div3TailNum\",\n",
    "    \"Div4Airport\",\n",
    "    \"Div4AirportID\",\n",
    "    \"Div4AirportSeqID\",\n",
    "    \"Div4WheelsOn\",\n",
    "    \"Div4TotalGTime\",\n",
    "    \"Div4LongestGTime\",\n",
    "    \"Div4WheelsOff\",\n",
    "    \"Div4TailNum\",\n",
    "    \"Div5Airport\",\n",
    "    \"Div5AirportID\",\n",
    "    \"Div5AirportSeqID\",\n",
    "    \"Div5WheelsOn\",\n",
    "    \"Div5TotalGTime\",\n",
    "    \"Div5LongestGTime\",\n",
    "    \"Div5WheelsOff\",\n",
    "    \"Div5TailNum\",\n",
    "]\n",
    "\n",
    "# Dropping the columns from the dataset\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Adjusting columns with redundant information already in other columns\n",
    "df['OriginCityName'] = df['OriginCityName'].str.split(',').str[0]\n",
    "df['DestCityName'] = df['DestCityName'].str.split(',').str[0]\n",
    "\n",
    "# Review the shape of the data\n",
    "print(f\"The resulting dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ],
   "id": "3aea816965b5979c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting dataset contains 2000000 rows and 63 columns.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The dataset covers two million flights during the period from __1987-10-01__ to __2020-03-31__. For the task, I'll be focusing on the data resulted in the last 2 decades.",
   "id": "2c4c0fc9217cdcda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:29:26.854196Z",
     "start_time": "2024-11-21T15:29:25.097785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Slicing the data to cover the last 2 decades\n",
    "df = df[(df[\"Year\"] > 1998) & (df[\"Year\"] < 2020)]\n",
    "\n",
    "# Review the shape of the data\n",
    "print(f\"The resulting dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ],
   "id": "1b369017226831cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting dataset contains 1376877 rows and 63 columns.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:31:10.910426Z",
     "start_time": "2024-11-21T15:30:16.387294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving the data for the dashboard\n",
    "df.to_csv(f'{path.parent}/data/airline_data_v1.0.csv')"
   ],
   "id": "e184d3fd563fc1ca",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "f7a24115",
   "metadata": {},
   "source": [
    "# That was it\n",
    "\n",
    "So that was in short our way to create an interactive multi-chart dashboard based on two input variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
